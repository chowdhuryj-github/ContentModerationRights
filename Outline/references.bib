@INPROCEEDINGS{1013833,
  author={Huff, C. and Johnson, D.G. and Miller, K.},
  booktitle={IEEE 2002 International Symposium on Technology and Society (ISTAS'02). Social Implications of Information and Communication Technology. Proceedings (Cat. No.02CH37293)}, 
  title={Virtual harms and virtual responsibility: a rape in cyberspace}, 
  year={2002},
  volume={},
  number={},
  pages={323-330},
  keywords={Virtual reality;Programming profession;Educational institutions;Ethics;Virtual environment;Multiuser detection;Databases;Hair;Software tools},
  doi={10.1109/ISTAS.2002.1013833}}

@phdthesis{mackinnon1992,
  author = {Richard C. MacKinnon},
  title = {Searching for the Leviathan in Usenet},
  year = {1992},
  school = {ProQuest Dissertations and Theses}, 
  note = {Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works; Last updated - 2023-02-20},
  abstract = {The purpose of this thesis is to identify signs of Thomas Hobbes' Leviathan in the Usenet computer conferencing network. Certainly nothing that the Usenet users can experience can compare to the Hobbesian scenario in which persons are forced to give up the right to govern themselves in exchange for personal safety. This is certainly true on the surface, but there is another level of interaction within Usenet other than user-to-user. It is the level of the users' "personae," and it is at this level of understanding that the fear of vanishing from existence is ever present and near. For personae within Usenet, life can be described as "solitary, poor, nasty, brutish, and short." And it is for their sakes that this researcher has searched for and found a Leviathan in Usenet.},
  keywords = {Philosophy, religion and theology; Communication and the arts; Social sciences; Applied sciences; Political science; Communication; Philosophy; Computer science; 0459:Communication; 0615:Political science; 0422:Philosophy; 0984:Computer science},
  isbn = {979-8-207-89610-6},
  language = {English},
  url = {https://msoe.idm.oclc.org/login?url=https://www.proquest.com/dissertations-theses/searching-leviathan-usenet/docview/304027876/se-2}
}

@article{tarleton2020,
    author = {Gillespie, Tarleton},
    year = {2020},
    month = {07},
    title = {Content moderation, AI, and the question of scale},
    journal = {Big Data \& Society},
    volume = {7},
    number = {2},
    note = {Copyright - © The Author(s) 2020. This work is licensed under the Creative Commons Attribution – Non-Commercial License https://creativecommons.org/licenses/by-nc/4.0/ (the “License”). Last updated - 2024-11-17},
    abstract = {AI seems like the perfect response to the growing challenges of content moderation on social media platforms: the immense scale of the data, the relentlessness of the violations, and the need for human judgments without wanting humans to have to make them. The push toward automated content moderation is often justified as a necessary response to the scale: the enormity of social media platforms like Facebook and YouTube stands as the reason why AI approaches are desirable, even inevitable. But even if we could effectively automate content moderation, it is not clear that we should.},
    keywords = {Computers--Electronic Data Processing, Artificial intelligence, bias, content moderation, platforms, scale, social media, Facebook, Moderation, YouTube, Content, Automation, Social networks, Content management, Digital media},
    language = {English},
    url = {https://msoe.idm.oclc.org/login?url=https://www.proquest.com/scholarly-journals/content-moderation-ai-question-scale/docview/2473716357/se-2},
}

@article{10.1145/3415178,
author = {Seering, Joseph},
title = {Reconsidering Self-Moderation: the Role of Research in Supporting Community-Based Models for Online Content Moderation},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {CSCW2},
url = {https://doi.org/10.1145/3415178},
doi = {10.1145/3415178},
abstract = {Research in online content moderation has a long history of exploring different forms that moderation can take, including both user-driven moderation models on community-based platforms like Wikipedia, Facebook Groups, and Reddit, and centralized corporate moderation models on platforms like Twitter and Instagram. In this work I review different approaches to moderation research with the goal of providing a roadmap for researchers studying community self-moderation. I contrast community-based moderation research with platforms and policies-focused moderation research, and argue that the former has an important role to play in shaping discussions about the future of online moderation. I provide six guiding questions for future research that, if answered, can support the development of a form of user-driven moderation that is widely implementable across a variety of social spaces online, offering an alternative to the corporate moderation models that dominate public debate and discussion.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {107},
numpages = {28},
keywords = {social networks, platforms, online communities, moderation, hate speech, harassment, governance}
}

@article{samples1972government,
  title={Why the Government Should Not Regulate Content Moderation of Social Media, 2019, April 9},
  author={Samples, J},
  journal={Retrieved from CATO Institute: https://www. cato. org/publications/policy-analysis/why-government-should-not-regulate-contentmoderation-social-media (2.12. 2020)},
  year={1972}
}

@article{dias2021,
    author = {Dias, Oliva T. and Antonialli, Dennys M. and Gomes, Alessandra},
    year = {2021},
    month = {04},
    title = {Fighting Hate Speech, Silencing Drag Queens? Artificial Intelligence in Content Moderation and Risks to LGBTQ Voices Online},
    journal = {Sexuality \& Culture},
    volume = {25},
    number = {2},
    pages = {700--732},
    note = {Copyright - © Springer Science+Business Media, LLC, part of Springer Nature 2020; Last updated - 2024-03-26},
    abstract = {Companies operating internet platforms are developing artificial intelligence tools for content moderation purposes. This paper discusses technologies developed to measure the ‘toxicity’ of text-based content. The research builds upon queer linguistic studies that have indicated the use of ‘mock impoliteness’ as a form of interaction employed by LGBTQ people to cope with hostility. Automated analyses that disregard such a pro-social function may, contrary to their intended design, actually reinforce harmful biases. This paper uses ‘Perspective’, an AI technology developed by Jigsaw (formerly Google Ideas), to measure the levels of toxicity of tweets from prominent drag queens in the United States. The research indicated that Perspective considered a significant number of drag queen Twitter accounts to have higher levels of toxicity than white nationalists. The qualitative analysis revealed that Perspective was not able to properly consider social context when measuring toxicity levels and failed to recognize cases in which words, that might conventionally be seen as offensive, conveyed different meanings in LGBTQ speech.},
    keywords = {Medical Sciences, Artificial intelligence, Twitter, Hate speech, Content moderation, Toxicity, Queer linguistics, Drag queens, Y, GenderWatch, Hostility, Content management, Qualitative research, Social environment, Social function, Technology, LGBTQ people, Nationalism, Drag (Performance)},
    isbn = {10955143},
    language = {English},
    url = {https://msoe.idm.oclc.org/login?url=https://www.proquest.com/scholarly-journals/fighting-hate-speech-silencing-drag-queens/docview/2495185828/se-2},
}

@inbook{prichard2002,
    author = {Prichard, H. A.},
    year = {2002},
    title = {Kant's Fundamental Principles of the Metaphysic of Morals},
    booktitle = {Moral Writings},
    publisher = {Oxford University Press},
    address = {Oxford},
    abstract = {Discusses central aspects of Kant's work on the nature of morality and the basis of moral obligation. In examining the categorical imperative and the hypothetical imperative, emphasizes the real nature of the distinction between these principles: whereas the former is binding upon everyone, the latter is binding only upon some individuals, namely those individuals who want the end for which a prescribed action is a means. Also considers the nature of the will, Kant's criterion of the rightness of a right action, and two criticisms of Kant's view of morality that arise from his attempt to offer a general answer to the question ‘Why ought an action be performed?’ Then turns to Kant's proof of freedom, which it is claimed just barely misses making the right point that action is only possible under the idea of freedom. Concludes by examining Kant's proof of immortality and the existence of God.},
    isbn = {9780199250196, 0199250197},
    language = {English},
}



@inbook{hobbes2018,
    author = {Hobbes, Thomas},
    year = {2018},
    title = {XIII: Of the Naturall Condition of Mankind, as Concerning Their Felicity, and Misery},
    booktitle = {Leviathan},
    publisher = {Lerner Publishing Group},
    address = {United States},
    language = {English},
}
